\chapter{Results and Discussion}
\label{sec:results}

\section{Results}

\section{Discussion}

\subsection{Unimodal}
In the case of TF-IDF, using all tags rather than only the ones that fall in the 1,500 most common generally performed better, with the exception of Agreeability. This shows that using all available information and taking less common nuances into account likely improves personality prediction. Between Word2Vec’s two averaging strategies, the one where post composition was prioritized (“Posts Weighed Equally”) performed better than the alternative, with the exception of Neuroticism; however, the difference  for that trait is minor. This could mean that taking overall post composition and sentiment into account, rather than just individual word usage, may reveal aspects of personality that are useful in its prediction. The combination of these two text features for personality prediction did not show any improvement over the individual results, with some results, most notably TF-IDF’s Neuroticism and Word2Vec’s Extraversion, performing better on their own.

Imagga and Resnet50 both had no notable results besides those for Consciousness and Extraversion, exemplifying a pattern among most, if not all, models in this study that these are the most accurately predicted personality traits. HSV results underperformed across the board, with the best results coming out just barely over 0, if at all. However, when combined with Resnet50, they yield some of the most notable results of the individual image modality, implying that this feature may still contain valuable personality data. However, this may also be because Resnet50 already had a strong baseline performance on its own, as it was not a major improvement from those results. 


\subsection{Bimodal}
From bimodal results, we can once more observe that Extraversion remains the easiest trait to predict, followed by Openness and Conscientiousness. Extraversion demonstrates the most consistent scores across combinations, suggesting that it exhibits stronger behavioral signals in social media compared to other traits. While Openness and Conscientiousness also showed promising results, they were less consistent. Agreeableness, while showing a few good results, was moderate overall. Lastly, Neuroticism once more proved to be the most difficult, with results clustering around zero or negative values. This pattern is consistent with prior personality computing studies, where internally experienced traits such as Neuroticism are less observable from external user-generated data.

In general, combining image and text modalities yields limited performance gains compared to unimodal performance. However, there was one significant improvement: the Word2Vec + HSV combination for Conscientiousness outperformed its parts individually, achieving a 0.2233 compared to their respective individual 0.1102 and 0.0115 scores. This suggests some complementary signal between semantic text features and low-level color statistics. However, this value did not outperform the overall best unimodal Conscientiousness model (0.2271 from TF-IDF) nor the overall best bimodal combinations discussed later. 

From the combination of the text and metadata modalities, some of the best-performing models among unimodal and bimodal models in this study are obtained. The combination of TF-IDF, Word2Vec, and metadata produced the best performance for Conscientiousness so far, with a kappa of 0.2451. The combination of Word2Vec and metadata also gave the current best model for Agreeability, with a kappa of 0.2129. These findings indicate that behavioral metadata provides informative personality cues that complement linguistic features. The improvement also suggests that user activity patterns may encode personality-relevant signals not fully captured by content alone.

The image-metadata combinations showed some improvement over their individual parts. Both ResNet50 + metadata and ResNet + HSV + metadata achieve $\kappa$ = 0.2807 for Extraversion. However, these still fall short of the best unimodal Extraversion model (Word2Vec, $\kappa$ = 0.3684), reinforcing the stronger predictive power of textual representations. We can also see from these combinations, as well as from unimodal performance, that the Conscientiousness trait appears to be more predictable with text, with most scores close to zero. The best score, 0.11, is just average compared to models that use text.

Overall, the results suggest that text—particularly semantic embeddings such as Word2Vec—remains the strongest modality for personality prediction in this dataset. While multimodal fusion shows potential, especially in Word2Vec + HSV and metadata-enhanced models, the gains are inconsistent. This may indicate partial redundancy between modalities or limitations in the current early-fusion strategy. Future work may benefit from more advanced fusion architectures or fine-tuned visual representations to better exploit cross-modal complementarities.

\subsection{Multimodal}

\section{Model Performance Analysis}
