\chapter{Results and Discussion}
\label{sec:results}

\section{Results}

\section{Discussion}

\subsection{Unimodal}
In the case of TF-IDF, using all tags rather than only the ones that fall in the 1,500 most common generally performed better, with the exception of Agreeability. This shows that using all available information and taking less common nuances into account likely improves personality prediction. Between Word2Vec’s two averaging strategies, the one that prioritized post composition (“Posts Weighed Equally”) performed better than the alternative, except for Neuroticism; however, the difference for that trait is minor. This could mean that taking overall post composition and sentiment into account, rather than just individual word usage, may reveal aspects of personality that are useful in its prediction. The combination of these two text features for personality prediction did not improve on the individual results, with some results, most notably TF-IDF’s Neuroticism and Word2Vec’s Extraversion, performing better on their own. These results show that TF-IDF and Word2Vec likely share overlapping personality information, which does not broaden our understanding but instead creates noise.

Imagga and Resnet50 both had no notable results besides those for Conscientiousness and Extraversion, exemplifying a pattern among most, if not all, models in this study that these are the most accurately predicted personality traits. Resnet also outperformed Imagga in those aspects by a noteworthy margin, meaning it is likely the more useful and informative representation of image data among the two. HSV results underperformed across the board, with the best results coming out just barely over 0, if at all. However, when combined with Resnet50, they yield some of the most notable results of the unimodal image models, implying that this feature still contains valuable personality data. However, this may also be because Resnet50 already had a strong baseline performance on its own, as the combination was not a major improvement on those results.

Despite the simplicity of the metadata feature, it yielded notable results, especially for the Openness model, which achieved a kappa of 0.22. This suggests that these features are still worth considering for personality prediction.


\subsection{Bimodal}
From bimodal results, we can once more observe that Extraversion remains the easiest trait to predict, followed by Openness and Conscientiousness. Extraversion demonstrates the most consistent scores across combinations, suggesting that it exhibits stronger behavioral signals in social media compared to other traits. While Openness and Conscientiousness also showed promising results, they were less consistent. Agreeableness, while showing a few good results, was moderate overall. Lastly, Neuroticism once more proved to be the most difficult, with results clustering around zero or negative values. This pattern is consistent with prior personality computing studies, where internally experienced traits such as Neuroticism are less observable from external user-generated data.

In general, combining image and text modalities yields limited performance gains compared to unimodal performance. However, there was one significant improvement: the Word2Vec + HSV combination for Conscientiousness outperformed its parts individually, achieving a kappa of 0.2233, compared to their respective kappa scores of 0.1102 and 0.0115. This suggests some complementary signal between semantic text features and low-level color statistics. However, this value did not outperform the overall best unimodal Conscientiousness model (0.2271 from TF-IDF).

From the combination of the text and metadata modalities, some of the best-performing models among unimodal and bimodal models in this study are obtained. The combination of TF-IDF, Word2Vec, and metadata produced the best performance for Conscientiousness so far, with a kappa of 0.2451. The combination of Word2Vec and metadata also gave the current best model for Agreeability, with a kappa of 0.2129. These findings indicate that behavioral metadata provides informative personality cues that complement linguistic features. The improvement also suggests that user activity patterns may contain personality-relevant signals not fully captured by content alone.

The image-metadata combinations showed some improvement over their individual parts. Both ResNet50 + metadata and ResNet + HSV + metadata achieve $\kappa$ = 0.2807 for Extraversion. However, these still fall short of the best unimodal Extraversion model (Word2Vec, $\kappa$ = 0.3684), reinforcing the stronger predictive power of textual representations. We can also see from these combinations, as well as from unimodal performance, that the Conscientiousness trait appears to be more predictable with text, with most scores close to zero. The best score, 0.11, is just average compared to models that use text. We can infer from that observation that textual features contain more valuable information for predicting the Conscientiousness trait.

Overall, the results suggest that text—particularly semantic embeddings such as Word2Vec—remains the strongest modality for personality prediction in this dataset. While multimodal fusion shows potential, especially in Word2Vec + HSV and metadata-enhanced models, the gains are inconsistent. This may indicate partial redundancy between modalities or limitations in the current early-fusion strategy. Future work may benefit from more advanced fusion architectures or fine-tuned visual representations to better exploit cross-modal complementarities.


\subsection{Multimodal}
The tri-modal results largely mirror the bimodal findings, as the relative difficulty of the traits remains unchanged. Extraversion continues to be the most predictable trait, followed by Openness and Conscientiousness, while Neuroticism remains consistently weak across all configurations. This indicates that increasing the number of modalities does not fundamentally alter trait learnability. Word2Vec-based text representations again show slightly better overall performance than TF-IDF, and combining the two provides limited additional benefit, although it does produce the best-performing models for Extraversion and Conscientiousness in this tri-modal setting. This may mean that personality-relevant signals are more strongly encoded in contextual semantic patterns than in raw word frequencies.

Examining the top-performing models per trait further highlights modality preferences. For Openness, the top configurations all rely on Word2Vec without TF-IDF, with Word2Vec + ResNet variants occupying most of the leading positions. Conscientiousness shows a stronger dependence on HSV features, with all HSV-only image configurations appearing in the top five of all trimodal models. This indicates that low-level aesthetic properties encode complementary personality signals for this trait. The best results largely come from single-image-feature setups, suggesting that Conscientiousness-related data may be redundant across image features and create noise when combined. Extraversion performance is dominated by ResNet-based models, typically paired with either Word2Vec, TF-IDF, or both, indicating the importance of high-level visual semantics for this trait. Agreeableness again favors the presence of Word2Vec in configurations, with some contribution from HSV and TF-IDF. In contrast, Neuroticism remains uniformly low across all tri-modal models, suggesting that the additional modality information does little to improve its predictability.

While some combinations show modest improvements over their bimodal counterparts, others exhibit negligible or inconsistent gains. In terms of overall performance, no trimodal model outperformed any bimodal or unimodal combination for any personality trait. Some individual combinations showed improvement as the number of modalities increased, most notably the Word2Vec + ResNet + Imagga combination, whose kappa increased from 0.1053 to 0.2105 when the metadata feature was combined, resulting in a 0.1052 increase in score. However, despite these improvements, it did not outperform the best-performing Extraversion model: a pure Word2Vec model using the “Posts Weighted Equally” averaging strategy with a kappa of 0.3684. Despite this, it may still be valuable to note that the increase in modality improved the performance of certain models.

\subsection{Overall}
An analysis of the top 10 models per trait reveals distinct modality patterns across personality dimensions. For Openness, the best-performing model is unimodal ResNet ($\kappa$ = 0.2726), and ResNet-based configurations appear in most of the top-ranked models. These are typically either pure ResNet or combinations of ResNet with metadata and HSV. Given that ResNet contributes 2,048 features compared to only 21 from HSV and 2 from metadata, it is likely that these multimodal configurations are largely driven by ResNet representations. This interpretation is supported by the fact that ResNet performs best on its own. The strongest non-ResNet model is unimodal Word2Vec ($\kappa$ = 0.2267), which also appears frequently among the top Openness models below the ResNet-dominated group, suggesting that semantic text features serve as a secondary but meaningful signal for this trait.

For Conscientiousness, the highest score comes from the bimodal TF-IDF + Word2Vec + metadata model ($\kappa$ = 0.2451). Most top configurations involve combinations of TF-IDF, Word2Vec, metadata, and HSV, with at least one textual representation always present.  Although metadata and HSV have relatively low dimensionality, their frequent appearance among high-performing configurations instead of the counterpart configurations that lack them suggests that they contribute useful complementary information rather than merely adding noise. Additionally, given the substantially higher dimensionality of textual features, Conscientiousness appears primarily text-driven, with metadata and HSV acting as supporting signals rather than dominant ones. Compared to Openness, image features are largely absent from the top models.

Extraversion is the overall best-performing trait, with unimodal Word2Vec (“Posts Weighted Equally”) achieving the highest kappa score of 0.3684. Similar to the Openness–ResNet pattern, Word2Vec performs best independently and is followed by combinations with HSV and metadata. ResNet also appears in several high-ranking combinations after the strongest Word2Vec-based models, indicating that visual features can provide additional gains. TF-IDF appears occasionally among top models but generally trails behind Word2Vec. 

For Agreeableness, the top-performing model is Word2Vec + metadata ($\kappa$ = 0.2129). Word2Vec appears in nearly all top configurations, typically combined with metadata, TF-IDF, or HSV. This pattern closely resembles Conscientiousness, where text forms the backbone of performance, and lower-dimensional features such as metadata and HSV frequently accompany it. As with Conscientiousness, these smaller feature sets appear to provide complementary value despite their limited dimensionality.

In contrast, Neuroticism shows a markedly different pattern. The best-performing model is unimodal TF-IDF ($\kappa$ = 0.1615), substantially outperforming the next highest model, Word2Vec + HSV ($\kappa$ = 0.0749). Beyond this leading result, most models cluster near zero. This trait has proven difficult to predict, no matter the combination of features or modalities.

From these rankings, some general observations can be made. Metadata and HSV frequently appear in high-performing combinations despite their low dimensionality. This raises two possibilities: either they add minimal noise and simply “ride along” with stronger high-dimensional features, or they provide compact but meaningful complementary signals. The substantial $\kappa$ increase observed in earlier experiments when adding only the two metadata features (+0.1052) supports the latter interpretation in at least some cases. Conversely, Imagga—despite having the largest dimensionality (36,398 features)—rarely appears among top-performing models. This suggests that high dimensionality alone does not guarantee predictive value and may instead introduce noise that limits its contribution. It may also suggest that Imagga does not carry a valuable amount of personality data.


\section{Model Performance Analysis}
The performance of the classification models—Logistic Regression (LR), Support Vector Machine (SVM), and XGBoost—was evaluated across various unimodal, bimodal, and multimodal feature combinations for each of the Big Five personality traits. The primary metric for evaluation was Cohen’s Kappa ($\kappa$), which accounts for the possibility of agreement occurring by chance.

\subsection{Performance by Trait}
Model performance varied significantly depending on the trait and the specific combination of features utilized.

\begin{itemize}
	\item \textbf{Extraversion:} This trait generally showed the strongest and most consistent predictive performance. In bimodal visual combinations such as Combination U7 (ResNet + Imagga), XGBoost achieved a test kappa of 0.2105. Performance peaked in multimodal settings, specifically Combination M1 (TF-IDF + ResNet + Metadata) using SVM, which yielded a test kappa of 0.2456.
	\item \textbf{Openness:} Predictive accuracy for Openness was highest when visual features were included. Combination U8 (ResNet + HSV) achieved a test kappa of 0.2762 with Logistic Regression, marking one of the highest scores across all experiments.
	\item \textbf{Conscientiousness:} This trait saw moderate performance. Combination B5 (TF-IDF + HSV) reached a test kappa of 0.1537 using Logistic Regression, while the addition of metadata in Combination M3 (TF-IDF + HSV + Metadata) slightly improved this to 0.1569.
	\item \textbf{Agreeableness and Neuroticism:} These traits proved the most challenging to predict. Results often yielded low or negative kappa values, suggesting that the selected features may not fully capture the nuances of these dimensions within the Filipino Instagram context. For instance, Neuroticism in Combination M1 resulted in a kappa of -0.0907.
\end{itemize}

\subsection{Comparison of Feature Fusion Approaches}
A key objective of this study was to determine if multimodal fusion improves prediction over unimodal or bimodal data.

\begin{itemize}
	\item \textbf{Bimodal Visual Combinations:} Combining different types of visual features (e.g., ResNet for deep features and HSV for color distribution) often improved performance over single-source visual sets. Combination U8 (ResNet + HSV) significantly outperformed U9 (Imagga + HSV) for both Openness and Extraversion.
	\item \textbf{Multimodal Fusion:} The integration of text (TF-IDF), images (ResNet/HSV), and account metadata generally provided more stable results across traits. Combination M4, which integrated TF-IDF, ResNet, Imagga, and Metadata, achieved a test kappa of 0.1264 for Openness. 
	\item \textbf{Overfitting Observations:} Despite high performance in certain categories, some bimodal text-image combinations faced issues with dimensionality (exceeding 38,000 features). This led to instances of overfitting, where high validation kappas (e.g., 0.8372 for Neuroticism in some XGBoost runs) did not translate to the test set, which remained negative.
\end{itemize}

\subsection{Algorithm Comparison}
The three models exhibited distinct performance characteristics across the dataset:

\begin{itemize}
	\item \textbf{XGBoost:} Frequently the top performer for Extraversion and Openness. It demonstrated a superior ability to handle complex, high-dimensional feature spaces, particularly in bimodal visual tasks.
	\item \textbf{Logistic Regression:} Performed best when metadata or HSV features were involved. This suggests that these specific features may have a more linear relationship with certain personality traits like Conscientiousness.
	\item \textbf{SVM:} Highly effective in specific multimodal configurations. It achieved the highest overall score for Extraversion in combinations M1 and M5, reaching a kappa of 0.2456.
\end{itemize}
