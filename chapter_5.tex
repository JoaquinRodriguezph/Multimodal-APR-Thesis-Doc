\chapter{Results and Discussion}
\label{sec:results}

\section{Results}
\begin{table}[H]
    \centering
    \caption{Best performing model in terms of Cohen's Kappa run on a testing data set in a specific combination of features per personality trait for each modality}
    \begin{tabularx}{\textwidth}{l|X|l|l}
    \hline
        \textbf{Trait} & \textbf{Combination} & \textbf{Model} & \textbf{Test Kappa} \\ \hline
        \multicolumn{4}{l}{\textbf{Unimodal}} \\ \hline
        \multicolumn{4}{l}{\textbf{Most Agreement}} \\ \hline
        Openness & Resnet50 + HSV & Logistic Regression (GPU) & 0.2762 \\ \hline
        Conscientiousness & Resnet50 + Imagga & XGBoost & 0.1174 \\ \hline
        Extraversion & Resnet50 + HSV & XGBoost & 0.2632 \\ \hline
        Agreeableness & Resnet50 + HSV & SVM (GPU) & 0.0444 \\ \hline
        Neuroticism & Resnet50 + HSV & SVM (GPU) & 0.0037 \\ \hline
        \multicolumn{4}{l}{\textbf{Most Disagreement}}\\ \hline
        Openness & Imagga + HSV & XGBoost & -0.0133 \\ \hline
        Conscientiousness & N/A & N/A & N/A \\ \hline
        Extraversion & N/A & N/A & N/A \\ \hline
        Agreeableness & Resnet50 + Imagga + HSV & Logistic Regression (GPU) & -0.1214 \\ \hline
        Neuroticism & Resnet50 + Imagga + HSV & SVM (GPU) & -0.0788 \\ \hline
    \end{tabularx}
    \label{bestcohenmodel}
\end{table}
\begin{table}[H]
    \centering
    \caption{Best performing model in terms of Cohen's Kappa run on a testing data set in a specific combination of features per personality trait for each modality}
    \begin{tabularx}{\textwidth}{l|X|l|l}
    \hline
        \textbf{Trait} & \textbf{Combination} & \textbf{Model} & \textbf{Test Kappa} \\ \hline
        \multicolumn{4}{l}{\textbf{Bimodal}} \\ \hline
        \multicolumn{4}{l}{\textbf{Most Agreement}} \\ \hline
        Openness & Resnet50 + HSV, Metadata & Logistic Regression (GPU) & 0.2602 \\ \hline
        Conscientiousness & TFIDF + Word2Vec, Metadata & SVM (GPU) & 0.2451 \\ \hline
        Extraversion & Word2Vec, HSV & Logistic Regression (GPU) & 0.3684 \\ \hline
        Agreeableness & Word2Vec, Metadata & SVM (GPU) & 0.2129 \\ \hline
        Neuroticism & Word2Vec, HSV & XGBoost & 0.0749 \\ \hline
        \multicolumn{4}{l}{\textbf{Most Disagreement}} \\ \hline
        Openness & TFIDF, Imagga & XGBoost & -0.0155 \\ \hline
        Conscientiousness & Resnet50, Metadata & XGBoost & -0.037 \\ \hline
        Extraversion & N/A & N/A & N/A \\ \hline
        Agreeableness & Resnet50 + Imagga, Metadata & Logistic Regression (GPU) & -0.1032 \\ \hline
        Neuroticism & Imagga + HSV, Metadata & XGBoost & -0.1259 \\ \hline
    \end{tabularx}
    \label{bestcohenmodel}
\end{table}
\begin{table}[H]
    \centering
    \caption{Best performing model in terms of Cohen's Kappa run on a testing data set in a specific combination of features per personality trait for each modality}
    \begin{tabularx}{\textwidth}{l|X|l|l}
    \hline
        \textbf{Trait} & \textbf{Combination} & \textbf{Model} & \textbf{Test Kappa} \\ \hline
        \multicolumn{4}{l}{\textbf{Multimodal}}\\ \hline
        \multicolumn{4}{l}{\textbf{Most Agreement}} \\ \hline
        Openness & Word2Vec, Resnet50 + Imagga + HSV, Metadata & XGBoost & 0.2267 \\ \hline
        Conscientiousness & TFIDF + Word2Vec, HSV, Metadata & SVM (GPU) & 0.2442 \\ \hline
        Extraversion & TFIDF + Word2Vec, Resnet50, Metadata & XGBoost & 0.2807 \\ \hline
        Agreeableness & Word2Vec, HSV, Metadata & SVM (GPU) & 0.1979 \\ \hline
        Neuroticism & Word2Vec, HSV, Metadata & XGBoost & 0.065 \\ \hline
        \multicolumn{4}{l}{\textbf{Most Disagreement}} \\ \hline
        Openness & N/A & N/A & N/A \\ \hline
        Conscientiousness & N/A & N/A & N/A \\ \hline
        Extraversion & N/A & N/A & N/A \\ \hline
        Agreeableness & Word2Vec, Resnet50, Metadata & XGBoost & -0.0201 \\ \hline
        Neuroticism & TFIDF, Imagga, Metadata & SVM & -0.1218 \\ \hline
    \end{tabularx}
    \label{bestcohenmodel}
\end{table}
\section{Discussion}

\subsection{Unimodal}
In the case of TF-IDF, using all tags rather than only the ones that fall in the 1,500 most common generally performed better, with the exception of Agreeability. This shows that using all available information and taking less common nuances into account likely improves personality prediction. Between Word2Vec’s two averaging strategies, the one that prioritized post composition (“Posts Weighed Equally”) performed better than the alternative, except for Neuroticism; however, the difference for that trait is minor. This could mean that taking overall post composition and sentiment into account, rather than just individual word usage, may reveal aspects of personality that are useful in its prediction. The combination of these two text features for personality prediction did not improve on the individual results, with some results, most notably TF-IDF’s Neuroticism and Word2Vec’s Extraversion, performing better on their own. These results show that TF-IDF and Word2Vec likely share overlapping personality information, which does not broaden our understanding but instead creates noise.

Imagga and Resnet50 both had no notable results besides those for Conscientiousness and Extraversion, exemplifying a pattern among most, if not all, models in this study that these are the most accurately predicted personality traits. Resnet also outperformed Imagga in those aspects by a noteworthy margin, meaning it is likely the more useful and informative representation of image data among the two. HSV results underperformed across the board, with the best results coming out just barely over 0, if at all. However, when combined with Resnet50, they yield some of the most notable results of the unimodal image models, implying that this feature still contains valuable personality data. However, this may also be because Resnet50 already had a strong baseline performance on its own, as the combination was not a major improvement on those results.

Despite the simplicity of the metadata feature, it yielded notable results, especially for the Openness model, which achieved a kappa of 0.22. This suggests that these features are still worth considering for personality prediction.


\subsection{Bimodal}
From bimodal results, we can once more observe that Extraversion remains the easiest trait to predict, followed by Openness and Conscientiousness. Extraversion demonstrates the most consistent scores across combinations, suggesting that it exhibits stronger behavioral signals in social media compared to other traits. While Openness and Conscientiousness also showed promising results, they were less consistent. Agreeableness, while showing a few good results, was moderate overall. Lastly, Neuroticism once more proved to be the most difficult, with results clustering around zero or negative values. This pattern is consistent with prior personality computing studies, where internally experienced traits such as Neuroticism are less observable from external user-generated data.

In general, combining image and text modalities yields limited performance gains compared to unimodal performance. However, there was one significant improvement: the Word2Vec + HSV combination for Conscientiousness outperformed its parts individually, achieving a kappa of 0.2233, compared to their respective kappa scores of 0.1102 and 0.0115. This suggests some complementary signal between semantic text features and low-level color statistics. However, this value did not outperform the overall best unimodal Conscientiousness model (0.2271 from TF-IDF).

From the combination of the text and metadata modalities, some of the best-performing models among unimodal and bimodal models in this study are obtained. The combination of TF-IDF, Word2Vec, and metadata produced the best performance for Conscientiousness so far, with a kappa of 0.2451. The combination of Word2Vec and metadata also gave the current best model for Agreeability, with a kappa of 0.2129. These findings indicate that behavioral metadata provides informative personality cues that complement linguistic features. The improvement also suggests that user activity patterns may contain personality-relevant signals not fully captured by content alone.

The image-metadata combinations showed some improvement over their individual parts. Both ResNet50 + metadata and ResNet + HSV + metadata achieve $\kappa$ = 0.2807 for Extraversion. However, these still fall short of the best unimodal Extraversion model (Word2Vec, $\kappa$ = 0.3684), reinforcing the stronger predictive power of textual representations. We can also see from these combinations, as well as from unimodal performance, that the Conscientiousness trait appears to be more predictable with text, with most scores close to zero. The best score, 0.11, is just average compared to models that use text. We can infer from that observation that textual features contain more valuable information for predicting the Conscientiousness trait.

Overall, the results suggest that text—particularly semantic embeddings such as Word2Vec—remains the strongest modality for personality prediction in this dataset. While multimodal fusion shows potential, especially in Word2Vec + HSV and metadata-enhanced models, the gains are inconsistent. This may indicate partial redundancy between modalities or limitations in the current early-fusion strategy. Future work may benefit from more advanced fusion architectures or fine-tuned visual representations to better exploit cross-modal complementarities.


\subsection{Multimodal}
The tri-modal results largely mirror the bimodal findings, as the relative difficulty of the traits remains unchanged. Extraversion continues to be the most predictable trait, followed by Openness and Conscientiousness, while Neuroticism remains consistently weak across all configurations. This indicates that increasing the number of modalities does not fundamentally alter trait learnability. Word2Vec-based text representations again show slightly better overall performance than TF-IDF, and combining the two provides limited additional benefit, although it does produce the best-performing models for Extraversion and Conscientiousness in this tri-modal setting. This may mean that personality-relevant signals are more strongly encoded in contextual semantic patterns than in raw word frequencies.

Examining the top-performing models per trait further highlights modality preferences. For Openness, the top configurations all rely on Word2Vec without TF-IDF, with Word2Vec + ResNet variants occupying most of the leading positions. Conscientiousness shows a stronger dependence on HSV features, with all HSV-only image configurations appearing in the top five of all trimodal models. This indicates that low-level aesthetic properties encode complementary personality signals for this trait. The best results largely come from single-image-feature setups, suggesting that Conscientiousness-related data may be redundant across image features and create noise when combined. Extraversion performance is dominated by ResNet-based models, typically paired with either Word2Vec, TF-IDF, or both, indicating the importance of high-level visual semantics for this trait. Agreeableness again favors the presence of Word2Vec in configurations, with some contribution from HSV and TF-IDF. In contrast, Neuroticism remains uniformly low across all tri-modal models, suggesting that the additional modality information does little to improve its predictability.

While some combinations show modest improvements over their bimodal counterparts, others exhibit negligible or inconsistent gains. In terms of overall performance, no trimodal model outperformed any bimodal or unimodal combination for any personality trait. Some individual combinations showed improvement as the number of modalities increased, most notably the Word2Vec + ResNet + Imagga combination, whose kappa increased from 0.1053 to 0.2105 when the metadata feature was combined, resulting in a 0.1052 increase in score. However, despite these improvements, it did not outperform the best-performing Extraversion model: a pure Word2Vec model using the “Posts Weighted Equally” averaging strategy with a kappa of 0.3684. Despite this, it may still be valuable to note that the increase in modality improved the performance of certain models.

\subsection{Overall}
An analysis of the top 10 models per trait reveals distinct modality patterns across personality dimensions. For Openness, the best-performing model is unimodal ResNet ($\kappa$ = 0.2726), and ResNet-based configurations appear in most of the top-ranked models. These are typically either pure ResNet or combinations of ResNet with metadata and HSV. Given that ResNet contributes 2,048 features compared to only 21 from HSV and 2 from metadata, it is likely that these multimodal configurations are largely driven by ResNet representations. This interpretation is supported by the fact that ResNet performs best on its own. The strongest non-ResNet model is unimodal Word2Vec ($\kappa$ = 0.2267), which also appears frequently among the top Openness models below the ResNet-dominated group, suggesting that semantic text features serve as a secondary but meaningful signal for this trait.

For Conscientiousness, the highest score comes from the bimodal TF-IDF + Word2Vec + metadata model ($\kappa$ = 0.2451). Most top configurations involve combinations of TF-IDF, Word2Vec, metadata, and HSV, with at least one textual representation always present.  Although metadata and HSV have relatively low dimensionality, their frequent appearance among high-performing configurations instead of the counterpart configurations that lack them suggests that they contribute useful complementary information rather than merely adding noise. Additionally, given the substantially higher dimensionality of textual features, Conscientiousness appears primarily text-driven, with metadata and HSV acting as supporting signals rather than dominant ones. Compared to Openness, image features are largely absent from the top models.

Extraversion is the overall best-performing trait, with unimodal Word2Vec (“Posts Weighted Equally”) achieving the highest kappa score of 0.3684. Similar to the Openness–ResNet pattern, Word2Vec performs best independently and is followed by combinations with HSV and metadata. ResNet also appears in several high-ranking combinations after the strongest Word2Vec-based models, indicating that visual features can provide additional gains. TF-IDF appears occasionally among top models but generally trails behind Word2Vec. 

For Agreeableness, the top-performing model is Word2Vec + metadata ($\kappa$ = 0.2129). Word2Vec appears in nearly all top configurations, typically combined with metadata, TF-IDF, or HSV. This pattern closely resembles Conscientiousness, where text forms the backbone of performance, and lower-dimensional features such as metadata and HSV frequently accompany it. As with Conscientiousness, these smaller feature sets appear to provide complementary value despite their limited dimensionality.

In contrast, Neuroticism shows a markedly different pattern. The best-performing model is unimodal TF-IDF ($\kappa$ = 0.1615), substantially outperforming the next highest model, Word2Vec + HSV ($\kappa$ = 0.0749). Beyond this leading result, most models cluster near zero. This trait has proven difficult to predict, no matter the combination of features or modalities.

From these rankings, some general observations can be made. Metadata and HSV frequently appear in high-performing combinations despite their low dimensionality. This raises two possibilities: either they add minimal noise and simply “ride along” with stronger high-dimensional features, or they provide compact but meaningful complementary signals. The substantial $\kappa$ increase observed in earlier experiments when adding only the two metadata features (+0.1052) supports the latter interpretation in at least some cases. Conversely, Imagga—despite having the largest dimensionality (36,398 features)—rarely appears among top-performing models. This suggests that high dimensionality alone does not guarantee predictive value and may instead introduce noise that limits its contribution. It may also suggest that Imagga does not carry a valuable amount of personality data.


\section{Model Performance Analysis}
The performance of the classification models Logistic Regression (LR), Support Vector Machine (SVM), and XGBoost was evaluated across various unimodal, bimodal, and multimodal feature combinations. The primary metric for evaluation was Cohen’s Kappa ($\kappa$), which measures the agreement between predicted and actual labels while accounting for chance.

\subsection{Performance by Trait}
The results indicate that while visual features often provide a strong predictive baseline, the addition of textual features (TF-IDF) and account metadata typically acts as a refinement layer, enhancing accuracy or providing necessary context.

\begin{itemize}
	\item \textbf{Extraversion:} This trait showed significant improvement when moving from purely visual bimodal sets to multimodal configurations. For instance, the bimodal combination of ResNet and Imagga (U7) achieved a test kappa of 0.2105 using XGBoost. However, the inclusion of linguistic features and metadata in Combination M1 (TF-IDF + ResNet + Metadata) pushed the performance higher, with SVM reaching a test kappa of 0.2456. This suggests that while visual cues are strong indicators of sociability, linguistic density and account activity provide the context needed for higher accuracy.
	
	\item \textbf{Openness:} Predictive accuracy for Openness was highest in visual-heavy combinations. Combination U8 (ResNet + HSV) achieved the peak test kappa of 0.2762 using Logistic Regression. Interestingly, adding more complex feature sets like TF-IDF and Metadata in Combination M1 led to a sharp decrease in performance to 0.0590. This indicates that for Openness, simple color distributions and deep visual features are the most reliable predictors, and adding high-dimensional text data may introduce noise.
	
	\item \textbf{Conscientiousness:} This trait benefited from the integration of metadata with textual and visual data. While Combination U7 reached a kappa of 0.1174, moving to Combination M3 (TF-IDF + HSV + Metadata) improved the result to 0.1569 using Logistic Regression. This suggests that the regularity of posting behavior captured in metadata complements the content-based features for this trait.
	
	\item \textbf{Agreeableness and Neuroticism:} These traits remained the most difficult to predict, frequently resulting in negative kappa values (e.g., -0.0907 for Neuroticism in Combination M1), suggesting that the current feature set may not fully capture the psychological indicators specific to these dimensions in the Filipino context.
\end{itemize}

\subsection{Stability of Multimodal Fusion}
In this analysis, stability is defined as the consistency of the model's predictive power across different trait-feature combinations, characterized by a narrower range of test kappa fluctuations and a higher frequency of positive results. 

The unimodal and bimodal visual sets (U7–U10) exhibited high volatility, with test kappa values swinging from 0.2762 to -0.1982. In contrast, Multimodal combinations (M1–M5) demonstrated greater stability. While they did not always reach the absolute highest peaks found in specialized visual sets, they maintained a more consistent positive range—predominantly between 0.05 and 0.24 for Openness, Conscientiousness, and Extraversion—and significantly reduced the frequency of extreme negative outliers compared to unimodal runs.

\subsection{Algorithm Comparison}
The three models were evaluated across 15 different feature combinations. Their performance is summarized below:

\begin{itemize}
	\item \textbf{XGBoost:} Top performer in 6 out of 15 combinations, primarily dominating in Extraversion and Openness. It proved most effective at handling non-linear relationships within bimodal visual data. However, it was also the most prone to overfitting on high-dimensional multimodal sets, where validation kappa reached 0.8372 while the test kappa remained negative.
	
	\item \textbf{Logistic Regression:} Most effective for Conscientiousness and Agreeableness, leading in 5 out of 15 combinations. It performed best when utilizing Metadata and HSV features, suggesting these features share a more linear relationship with "orderly" personality traits.
	
	\item \textbf{SVM:} Best in 4 out of 15 combinations, specifically those involving Multimodal Fusion (M1, M2, M4, and M5). It achieved the highest overall score for Extraversion ($\kappa = 0.2456$). SVM demonstrated a superior ability to find optimal hyperplanes in the high-dimensional space created when combining linguistic features with deep visual data.
\end{itemize}
