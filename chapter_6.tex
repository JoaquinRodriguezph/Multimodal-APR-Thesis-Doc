\chapter{Conclusion and Recommendations}

\section{Conclusion}

This research developed and evaluated a multimodal framework for Automatic Personality Recognition (APR) of Filipino Instagram users using the PagkataoKo dataset. The study pursued six objectives: finalizing a suitable data subset, identifying relevant data characteristics, extracting multimodal features, building prediction models, identifying indicative features per trait, and evaluating performance against unimodal approaches.

The feature extraction process generated three modality streams: visual features from ResNet50, HSV color analysis, and Imagga object tags; textual features from TF-IDF and Word2Vec; and behavioral metadata from post and following counts. These were combined through early fusion and used to train Logistic Regression, SVM, and XGBoost classifiers for each Big Five trait.

The results reveal that optimal feature sets vary across personality traits:

\begin{itemize}
	
	\item \textbf{Openness} was best predicted by visual features alone (\(\kappa = 0.2762\)), specifically ResNet50 and HSV.
	
	\item \textbf{Conscientiousness} benefited from a mixed-feature approach (\(\kappa = 0.2451\)), combining TF-IDF, Word2Vec, and metadata with SVM. This suggests that organized behavior is expressed through both specific word choices and posting regularity.
	
	\item \textbf{Extraversion} achieved the strongest performance (\(\kappa = 0.3684\)) using Word2Vec and HSV features with Logistic Regression.
	
	\item \textbf{Agreeableness} was best captured by Word2Vec, HSV, and metadata with SVM (\(\kappa = 0.1979\)).
	
	\item \textbf{Neuroticism} proved most challenging, with unimodal TF-IDF achieving the highest performance (\(\kappa = 0.1615\)).
	
\end{itemize}

Only the personality traits Openness, Conscientiousness, and Extraversion garnered a fair kappa score (0.21 and above). Agreeableness and Neuroticism proved difficult.

Several key findings emerge from this work. First, predictive performance is inherently trait-dependent: no single modality or feature type dominates across all five dimensions. Second, while multimodal fusion generally enhances robustness, certain traits—particularly Neuroticism and Openness—are most effectively captured through specific unimodal features; TF-IDF for Neuroticism, and Resnet50 and HSV features for Openness. Third, metadata features, though only being two features, improved the performance for Conscientiousness and Agreeableness. Conscientiousness had a + 0.0491 kappa improvement, while Agreeableness had a +.0199 kappa improvement. Fourth, the Imagga object tags yielded negligible predictive value across all traits, suggesting that either the tag set lacks data that can predict personality effectively or that alternative image features may be more effective.

These findings advance Filipino APR by demonstrating that mixed-feature approaches—combining text, image, and metadata features— can improve predictive performance. The work also establishes that Instagram's multimodal nature provides complementary personality signals that text-only Twitter-based studies cannot capture.
\section{Recommendations}
\label{sec:recommendations}

Future research should explore using multimodal features as well. While this study identified that some traits work better unimodal (Openness and Neuroticism), others perform better when multimodal is used. Regarding model architectures, the findings suggest a transition toward more complex systems. While the current dataset size might make standard Multilayer Perceptrons (MLPs) less effective, the use of multimodal fusion networks can be further utilized for capturing non-linear relationships between image and text data.

Specific technical improvements can also be made to the feature extraction process. For text features, exploring Convolutional Neural Networks (CNNs) could capture local context more effectively and push the performance of Word2Vec embeddings further. Additionally, since the domain of social media data often differs from standard training sets, exploring other pre-trained transformers could bridge this gap. For image features, while ResNet provided strong semantic features, the Imagga tags yielded negligible improvements. Future work should look into alternative objective detection algorithms or open-source visual models, especially since Imagga is a private tool.

