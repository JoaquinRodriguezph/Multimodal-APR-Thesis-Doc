\chapter{Conclusion and Recommendations}

\section{Conclusion}

In summary, this research conducted a series of experiments to investigate the correlation between Instagram activity and the Big Five personality traits using the PagkataoKo dataset. The study began by finalizing a specific subset of data points and identifying key characteristics relevant to Automatic Personality Recognition. Following this, feature extraction was performed using a multimodal approach: visual features were captured through Imagga, ResNet50, and HSV, textual data was processed using TF-IDF and Word2Vec, and metadata features used were the user's post count, and following count. These features were used in training machine learning models: Logistic Regression, Support Vector Machines, and XGBoost, to determine which combinations of modalities and algorithms best predict personality.

The results, as measured by Cohen's kappa ($\kappa$), indicate that the effectiveness of personality prediction is highly trait-dependent. As shown in Table~\ref{tab:conclusion_results}, Extraversion proved to be the most accurately predicted trait, achieving the highest kappa score of 0.3684 using a combination of Word2Vec and HSV features. While multimodal approaches—combining visual and textual data—yielded superior results for Conscientiousness, Extraversion, and Agreeableness, there were two outliers. Openness performed its best using image features, namely Resnet50 and HSV.  On the other hand, Neuroticism performed its best using purely TF-IDF features. This suggests that while combining features from different modalities are powerful predictors for most traits, certain personality traits remain more effectively expressed through unimodal features.

Beyond raw performance, the study highlighted a significant trade-off between predictive power and interpretability. While deep learning-based features like ResNet50 and Word2Vec consistently drove the highest accuracy, they offered less transparency regarding why specific features were indicative of a trait. In contrast, TF-IDF provided more clear and interpretable tags. Additionally, it was observed that while metadata was included in several top-performing models, its overall influence was minimal compared to the core visual and textual embeddings. Ultimately, this research demonstrates that while a multimodal approach generally enhances APR performance,  unimodal approaches still outshine in other traits..

\section{Recommendations}
\label{sec:recommendations}

This study recognizes that there are areas which could be further explored to improve the performance of the models, as well as to contribute to a more deeper understanding of APR.
Based on the limitations and findings of this study, the following recommendations are proposed for future research:

Firstly, future work should transition toward more complex model architectures, specifically neural networks. Given the high performance of ResNet50 and Word2Vec embeddings, implementing deep learning models—such as Multi-Layer Perceptrons (MLP) or multimodal fusion networks—could potentially capture the intricate, non-linear relationships between visual and textual data more effectively than traditional algorithms. This shift could help maximize the predictive potential of the high-dimensional feature sets identified in this research.

Second, the feature selection process in future iterations should be streamlined by excluding low-impact modalities. This study found that \textbf{Imagga} visual descriptors and \textbf{metadata} features (post count and following count) provided negligible improvements to model performance across most personality traits. Future researchers should prioritize computational efficiency and model simplicity by focusing on the core high-performing features, namely ResNet, TF-IDF, and Word2Vec. This pruning would allow for faster model training and reduce the risk of overfitting to noisy, non-predictive data points.

Lastly, the exploration of alternative or more specialized feature extraction methods remains highly encouraged to improve predictive accuracy. While this study utilized standard linguistic and aesthetic features, future work could investigate task-specific visual models, such as those pre-trained on artistic style or photographic aesthetics, rather than generic object recognition (e.g. Neural IMage Assessment (Google), AVA (Aesthetic Visual Analysis) Models). For textual data, although this research utilized Word2Vec for semantic embeddings, the transition to transformer-based models like BERT or RoBERTa could be explored. These models capture deeper bidirectional context and linguistic nuance which might provide a more sophisticated understanding of personality-driven language patterns compared to traditional word embeddings