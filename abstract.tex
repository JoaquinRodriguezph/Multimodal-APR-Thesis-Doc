%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   Filename    : abstract.tex 
%
%   Description : This file will contain your abstract.
%                 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
%% \begin{mdframed} [style=highlight]
Filipino Automatic Personality Recognition (APR) is a growing field that has primarily relied on unimodal textual analysis from platforms like X (formerly Twitter), despite evidence that integrating visual and linguistic cues significantly improves trait prediction accuracy. This study addresses the gap in multimodal research within the Philippine context by developing an APR framework for Instagram users that combines image features, bilingual (English/Tagalog) text, and account metadata. Utilizing classification models such as SVM and XGBoost with feature-level fusion, the research compares the effectiveness of unimodal and multimodal approaches across the Big Five personality traits using the PagkataoKo dataset. The results demonstrate that predictive performance is highly trait-dependent: textual features like TF-IDF and Word2Vec are the primary drivers for Conscientiousness, Agreeableness, and Neuroticism, while visual features such as ResNet and HSV dominate for Openness and Extraversion. Furthermore, while multimodal integration generally enhances robustness and metadata provides a crucial refinement for behavioral regularities, certain traits remain most effectively captured through specific unimodal channels.
%% \end{mdframed}




%
%  Do not put citations or quotes in the abract.
%
\end{abstract}
